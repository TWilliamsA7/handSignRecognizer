{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc8a8b7-c200-4a4c-a211-ef6cb87c54bf",
   "metadata": {},
   "source": [
    "# Hand Sign Recognition - Train Model\n",
    "\n",
    "This notebook is used to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e124f54-11e3-424c-a8e3-d9b23eb79c85",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572182d-7bbf-48f0-9c16-8406017684bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4540d38d-4faf-4515-aacb-8198519038ae",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cefa89-ffda-4b2b-aa79-68f38f7b24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"..\") / \"data\" / \"processed\"\n",
    "IMG_SIZE = 128\n",
    "\n",
    "def load_data():\n",
    "    X = []\n",
    "    y = []\n",
    "    label_map = {}\n",
    "    i = 0\n",
    "\n",
    "    # For each label directory in the data/processed directory\n",
    "    for label_dir in DATA_DIR.iterdir():\n",
    "        if not label_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        label = label_dir.name\n",
    "        label_map[i] = label\n",
    "\n",
    "        # For each image file in the label directory\n",
    "        for img_file in label_dir.glob(\"*.jpg\"):\n",
    "            img = cv2.imread(str(img_file))\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Add the processed image into array with label index\n",
    "            X.append(img)\n",
    "            y.append(i)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Normalize Pixel values to be between 1 and 0\n",
    "    X = np.array(X) / 255.0\n",
    "    y = np.array(y)\n",
    "    return X, y, label_map\n",
    "\n",
    "X, y, label_map = load_data()\n",
    "print(f\"Loaded {len(X)} images across {len(label_map)} labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312673c2-4905-49ef-b27a-deb92cba1dc2",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b5b73-e8a1-46fd-82a3-333d0aeda288",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc95ae8-07e5-49b6-a038-18fc649b54a1",
   "metadata": {},
   "source": [
    "## Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e89008-e14b-4e66-a324-3d481f01852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model((IMG_SIZE, IMG_SIZE, 3), num_classes=len(label_map))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48dc65-4cb3-4bd8-8413-9d7d82a8df6d",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194d7b8-c592-4511-a07f-0cdd35eda743",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756cfd53-e165-49fd-b1e4-b3d350126b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=12,\n",
    "    batch_size=16,\n",
    "    callbacks=[lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0feb54-fdc9-4e27-ad37-1762e5f77f36",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea0365-00fd-4efb-8eec-b982f3b2f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot Accuracy Over Epochs\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss Over Epochs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff5e38-af19-4082-b9a6-f748d11eb771",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b423b0d-278a-458d-b06d-90873d74c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(\"..\") / \"models\"\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "model.save(MODEL_DIR / \"cnn_hand_sign_model_05.h5\")\n",
    "print(\"âœ… Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342b267-6154-4cda-8c79-3862d16f3b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
